# Advanced-Machine-Learning-Materials
This repository contains advanced machine learning projects from my coursework under Professor Mingrui Liu. It covers various techniques, from traditional algorithms to deep learning models, focusing on data preprocessing, model development, optimization, and evaluation. Explore the code and insights from these experiments!

# cs782_Hw1 (1).pdf
This file contains the first homework assignment for the CS 782 Advanced Machine Learning course. It focuses on probability bounds for eigenvalue estimation and includes theoretical derivations and empirical verifications using code. Topics include matrix concentration inequalities, Weyl’s inequality, and empirical probability estimation via code simulations​(cs782_Hw1 (1)).

# cs782_Hw2.pdf
This file includes the second homework assignment, which deals with matrix factorization problems. It covers optimization tasks such as minimizing the Frobenius norm and analyzes the stationary points of functions, gradient descent methods, and their classifications (e.g., local minima, saddle points). The file also features gradient descent simulations using Python code​(cs782_Hw2)​(cs782_Hw3 (1)).

# cs782_Hw3 (1).pdf / cs782_Hw3.pdf
These files pertain to the third homework, focusing on matrix completion problems. The homework explains optimization techniques like stochastic gradient descent to reconstruct matrices with missing entries. It explores performance metrics like the nuclear norm and matrix rank, with experimental results presented through plots that analyze different matrix dimensions and the effectiveness of matrix completion algorithms​(cs782_Hw3 (1))​(cs782_Hw3).

# cs782_Hw4 (1).pdf
The fourth homework discusses transfer learning techniques using the AlexNet model. Two approaches are examined: modifying the final layer for representation learning and full fine-tuning of all layers. The file includes detailed code, performance analysis, and training metrics, such as validation loss and test accuracy, comparing both methods in the context of classifying the CIFAR-10 dataset​(cs782_Hw4 (1)).


# 782_Final_Survey (6).pdf:

This file is a survey paper titled **"Fairness and Transparency in Large Language Models"** co-authored by Franklin CD Samuel and Gaurab Pokharel. The paper presents a comprehensive examination of fairness and transparency in Large Language Models (LLMs), exploring how these models can inherit societal biases from their training data. It discusses various phases where bias can occur, such as data collection, algorithm design, and model implementation. The survey categorizes existing bias mitigation techniques into pre-processing, in-processing, and post-processing strategies, covering efforts from bias-free data collection to adjusting model outputs for fairness. The paper also highlights open challenges and proposes directions for future research, emphasizing the importance of interdisciplinary collaboration and regulatory frameworks to ensure that AI technologies are both transparent and equitable
